{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import glob\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.72s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=0.04s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=0.04s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 13231/13231 [08:05<00:00, 27.24it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 1691/1691 [01:20<00:00, 21.03it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 1685/1685 [01:18<00:00, 21.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.54s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=0.03s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=0.26s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 12753/12753 [08:16<00:00, 25.67it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 1548/1548 [00:47<00:00, 32.27it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 1631/1631 [00:49<00:00, 32.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=1.67s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=0.10s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=0.67s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 47751/47751 [59:21<00:00, 13.41it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 5975/5975 [06:16<00:00, 15.89it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 5937/5937 [05:51<00:00, 16.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=2.69s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=0.62s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=0.08s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 17865/17865 [19:32<00:00, 15.23it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 2190/2190 [00:37<00:00, 59.13it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 2240/2240 [00:38<00:00, 58.55it/s]\n"
     ]
    }
   ],
   "source": [
    "### cocodata를 활용하여 각 파손별 및 train/test/val 별 마스크 생성하기 ###\n",
    "### grayscale로 mask 생성 ###\n",
    "\n",
    "import json\n",
    "\n",
    "from pycocotools.coco import COCO\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import os\n",
    "import random\n",
    "import shutil\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "\n",
    "catego = ['Breakage', 'Crushed', 'Scratched', 'Separated']\n",
    "img_origin = '../data/Dataset/1.원천데이터/damage/'\n",
    "json_origin = '../data/Dataset/2.라벨링데이터/damage/'\n",
    "\n",
    "\n",
    "for c in catego:\n",
    "        part_json = '../data/datainfo/damage_' + c + '_train.json'\n",
    "        test_json = '../data/datainfo/damage_' + c + '_test.json'\n",
    "        val_json  = '../data/datainfo/damage_' + c + '_val.json'\n",
    "\n",
    "        with open(part_json, 'r') as f:\n",
    "                trpart = json.load(f)\n",
    "\n",
    "        with open(test_json, 'r') as f:\n",
    "                tepart = json.load(f)\n",
    "\n",
    "        with open(val_json, 'r') as f:\n",
    "                vapart = json.load(f)        \n",
    "\n",
    "        coco = COCO(part_json)\n",
    "        coco2 = COCO(test_json)\n",
    "        coco3 = COCO(val_json)\n",
    "\n",
    "        img_ids = coco.getImgIds()\n",
    "        img_id2 = coco2.getImgIds()\n",
    "        img_id3 = coco3.getImgIds()\n",
    "\n",
    "        cate = {c : []}\n",
    "        cate_color =  (random.randrange(0, 256), random.randrange(0, 256), random.randrange(0, 256))\n",
    "\n",
    "        for i in tqdm(range(0, len(trpart['images']))):\n",
    "                id = int(img_ids[i])\n",
    "                image_name = trpart['images'][i]['file_name']\n",
    "                if not os.path.exists('../data/Dataset/damage_type/' + c + '_img_train/') and not os.path.exists('../data/Dataset/damage_type/' + c + '_json_train/'):\n",
    "                        os.makedirs('../data/Dataset/damage_type/' + c + '_img_train/')\n",
    "                        os.makedirs('../data/Dataset/damage_type/' + c + '_json_train/')\n",
    "                shutil.copyfile(img_origin + image_name, '../data/Dataset/damage_type/' + c + '_img_train/' + image_name)\n",
    "                shutil.copyfile(json_origin + image_name.replace('.jpg', '.json'), '../data/Dataset/damage_type/' + c + '_json_train/' + image_name.replace('.jpg', '.json'))\n",
    "                image_infos = coco.loadImgs(id)[0]\n",
    "                width = image_infos['width']\n",
    "                height = image_infos['height']\n",
    "\n",
    "                for j in range(0, len(trpart['annotations'])):\n",
    "                        if trpart['annotations'][j]['image_id'] == id:\n",
    "                                if len(trpart['annotations'][j]['segmentation'][0]) > 1:\n",
    "                                        for i in trpart['annotations'][j]['segmentation'][0]:\n",
    "                                                if trpart['annotations'][j]['damage'] in cate.keys():\n",
    "                                                        cate[trpart['annotations'][j]['damage']].append(i)\n",
    "                                else:\n",
    "                                        if trpart['annotations'][j]['damage'] in cate.keys():\n",
    "                                                cate[trpart['annotations'][j]['damage']].append(trpart['annotations'][j]['segmentation'][0][0])\n",
    "\n",
    "                mask = np.zeros((height,width, 3),dtype = np.uint8)\n",
    "                if not os.path.exists('../data/Dataset/damage_mask/' + c + '_train_mask/'):\n",
    "                        os.makedirs('../data/Dataset/damage_mask/' + c + '_train_mask/')\n",
    "                for j in range(0, len(cate[c])):\n",
    "                        mask = cv2.fillPoly(mask, [np.array(cate[c][j][0])], cate_color)\n",
    "                cv2.imwrite(f'../data/Dataset/damage_mask/' + c + '_train_mask/' + image_name.replace('.jpg', '') + '.png', cv2.cvtColor(mask, cv2.COLOR_RGB2GRAY))\n",
    "                cate[c] = []\n",
    "        \n",
    "        for i in tqdm(range(0, len(tepart['images']))):\n",
    "                id = int(img_id2[i])\n",
    "                image_name = tepart['images'][i]['file_name']\n",
    "                if not os.path.exists('../data/Dataset/damage_type/' + c + '_img_test/') and not os.path.exists('../data/Dataset/damage_type/' + c + '_json_test/'):\n",
    "                        os.makedirs('../data/Dataset/damage_type/' + c + '_img_test/')\n",
    "                        os.makedirs('../data/Dataset/damage_type/' + c + '_json_test/')\n",
    "                shutil.copyfile(img_origin + image_name, '../data/Dataset/damage_type/' + c + '_img_test/' + image_name)\n",
    "                shutil.copyfile(json_origin + image_name.replace('.jpg', '.json'), '../data/Dataset/damage_type/' + c + '_json_test/' + image_name.replace('.jpg', '.json'))\n",
    "                image_infos = coco2.loadImgs(id)[0]\n",
    "                width = image_infos['width']\n",
    "                height = image_infos['height']\n",
    "\n",
    "                for j in range(0, len(tepart['annotations'])):\n",
    "                        if tepart['annotations'][j]['image_id'] == id:\n",
    "                                if len(tepart['annotations'][j]['segmentation'][0]) > 1:\n",
    "                                        for i in tepart['annotations'][j]['segmentation'][0]:\n",
    "                                                if tepart['annotations'][j]['damage'] in cate.keys():\n",
    "                                                        cate[tepart['annotations'][j]['damage']].append(i)\n",
    "                                else:\n",
    "                                        if tepart['annotations'][j]['damage'] in cate.keys():\n",
    "                                                cate[tepart['annotations'][j]['damage']].append(tepart['annotations'][j]['segmentation'][0][0])\n",
    "\n",
    "                mask = np.zeros((height,width, 3),dtype = np.uint8)\n",
    "                if not os.path.exists('../data/Dataset/damage_mask/' + c + '_test_mask/'):\n",
    "                        os.makedirs('../data/Dataset/damage_mask/' + c + '_test_mask/')\n",
    "                for j in range(0, len(cate[c])):\n",
    "                        mask = cv2.fillPoly(mask, [np.array(cate[c][j][0])], cate_color)\n",
    "                cv2.imwrite(f'../data/Dataset/damage_mask/' + c + '_test_mask/' + image_name.replace('.jpg', '') + '.png', cv2.cvtColor(mask, cv2.COLOR_RGB2GRAY))\n",
    "                cate[c] = []\n",
    "\n",
    "        for i in tqdm(range(0, len(vapart['images']))):\n",
    "                id = int(img_id3[i])\n",
    "                image_name = vapart['images'][i]['file_name']\n",
    "                if not os.path.exists('../data/Dataset/damage_type/' + c + '_img_val/') and not os.path.exists('../data/Dataset/damage_type/' + c + '_json_val/'):\n",
    "                        os.makedirs('../data/Dataset/damage_type/' + c + '_img_val/')\\compute\\tpus\n",
    "                        os.makedirs('../data/Dataset/damage_type/' + c + '_json_val/')\n",
    "                shutil.copyfile(img_origin + image_name, '../data/Dataset/damage_type/' + c + '_img_val/' + image_name)\n",
    "                shutil.copyfile(json_origin + image_name.replace('.jpg', '.json'), '../data/Dataset/damage_type/' + c + '_json_val/' + image_name.replace('.jpg', '.json'))\n",
    "                image_infos = coco3.loadImgs(id)[0]\n",
    "                width = image_infos['width']\n",
    "                height = image_infos['height']\n",
    "\n",
    "                for j in range(0, len(vapart['annotations'])):\n",
    "                        if vapart['annotations'][j]['image_id'] == id:\n",
    "                                if len(vapart['annotations'][j]['segmentation'][0]) > 1:\n",
    "                                        for i in vapart['annotations'][j]['segmentation'][0]:\n",
    "                                                if vapart['annotations'][j]['damage'] in cate.keys():\n",
    "                                                        cate[vapart['annotations'][j]['damage']].append(i)\n",
    "                                else:\n",
    "                                        if vapart['annotations'][j]['damage'] in cate.keys():\n",
    "                                                cate[vapart['annotations'][j]['damage']].append(vapart['annotations'][j]['segmentation'][0][0])\n",
    "\n",
    "                mask = np.zeros((height,width, 3),dtype = np.uint8)\n",
    "                if not os.path.exists('../data/Dataset/damage_mask/' + c + '_val_mask/'):\n",
    "                        os.makedirs('../data/Dataset/damage_mask/' + c + '_val_mask/')\n",
    "                for j in range(0, len(cate[c])):\n",
    "                        mask = cv2.fillPoly(mask, [np.array(cate[c][j][0])], cate_color)\n",
    "                cv2.imwrite(f'../data/Dataset/damage_mask/' + c + '_val_mask/' + image_name.replace('.jpg', '') + '.png', cv2.cvtColor(mask, cv2.COLOR_RGB2GRAY))\n",
    "                cate[c] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pycocotools\n",
      "  Downloading pycocotools-2.0.6.tar.gz (24 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "    Preparing wheel metadata: started\n",
      "    Preparing wheel metadata: finished with status 'done'\n",
      "Requirement already satisfied: matplotlib>=2.1.0 in a:\\anaconda\\lib\\site-packages (from pycocotools) (3.4.3)\n",
      "Requirement already satisfied: numpy in a:\\anaconda\\lib\\site-packages (from pycocotools) (1.20.3)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in a:\\anaconda\\lib\\site-packages (from matplotlib>=2.1.0->pycocotools) (3.0.4)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in a:\\anaconda\\lib\\site-packages (from matplotlib>=2.1.0->pycocotools) (1.3.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in a:\\anaconda\\lib\\site-packages (from matplotlib>=2.1.0->pycocotools) (8.4.0)\n",
      "Requirement already satisfied: cycler>=0.10 in a:\\anaconda\\lib\\site-packages (from matplotlib>=2.1.0->pycocotools) (0.10.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in a:\\anaconda\\lib\\site-packages (from matplotlib>=2.1.0->pycocotools) (2.8.2)\n",
      "Requirement already satisfied: six in a:\\anaconda\\lib\\site-packages (from cycler>=0.10->matplotlib>=2.1.0->pycocotools) (1.16.0)\n",
      "Building wheels for collected packages: pycocotools\n",
      "  Building wheel for pycocotools (PEP 517): started\n",
      "  Building wheel for pycocotools (PEP 517): finished with status 'done'\n",
      "  Created wheel for pycocotools: filename=pycocotools-2.0.6-cp39-cp39-win_amd64.whl size=77744 sha256=8d7be82d669a60760ff37b44247f982a32521126fb0fb0016627c4eb8991f0b4\n",
      "  Stored in directory: c:\\users\\shs03\\appdata\\local\\pip\\cache\\wheels\\2f\\58\\25\\e78f1f766e904a9071266661d20d0bc6644df86bcd160aba11\n",
      "Successfully built pycocotools\n",
      "Installing collected packages: pycocotools\n",
      "Successfully installed pycocotools-2.0.6\n"
     ]
    }
   ],
   "source": [
    "!pip install pycocotools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('./data/datainfo/damage_Breakage_train.json', 'r') as f:\n",
    "        part = json.load(f)\n",
    "\n",
    "len(part['images'])\n",
    "\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "from pycocotools.coco import COCO\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "part_json = './data/datainfo/damage_Breakage_train.json'\n",
    "\n",
    "coco = COCO(part_json)\n",
    "\n",
    "img_ids = coco.getImgIds()\n",
    "\n",
    "for i in range(0, len(part['images'])):\n",
    "        image_id = int(img_ids[i])\n",
    "\n",
    "        image_infos = coco.loadImgs(image_id)[0]\n",
    "        width = image_infos['width']\n",
    "        height = image_infos['height']\n",
    "        \n",
    "\n",
    "        image_seg = coco.loadAnns(image_id)[0]['segmentation']\n",
    "        mask = np.zeros((width,height, 3),dtype = np.uint8)\n",
    "        tmp_list =[]\n",
    "        for i in range(len(image_seg[0][0])):\n",
    "               tmp_list.append(np.array(image_seg[0][0][i])) \n",
    "        \n",
    "        print(tmp_list)\n",
    "        cv2.fillPoly(mask,tmp_list, (0,0,255))\n",
    "        cv2.imwrite(f'{image_id}.png', mask)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0 (default, Jun 28 2018, 08:04:48) [MSC v.1912 64 bit (AMD64)]"
  },
  "vscode": {
   "interpreter": {
    "hash": "3bcade516a31772df401282903d78df2ec3803ffaa7dc98ac3d0b85bcc235db4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
